import inspect
import pdb

class Instruction:
    def __init__(self, command, operand):
        self.command = command
        self.operand = operand if operand is not None else ''
        
def p():
    pass

def p2(x,y):
    pass

pdb.set_trace = p

"""
@package recursive_decent_parser
This parses the tokens generated by the Lexer
"""
import sys
from lexicalanalyzer import Lexer

index = 0
num_double_at = 0

MAX_DOUBLE_AT = 2

ERROR_STRING = '\nError on line {1}\nToken type is "{2}"\nLexeme is "{3}"\nDescription: {0}\n'
INPUT_FILE = ''

CURRENT_DATA_TYPE = None
CURRENT_MEMORY_LOCATION = 1000

OUTPUT_FILE = None

PrintParseInfo = None
PrintCurrentTokenInfo = None

INSTRUCTIONS = []
SYMBOL_TABLE = []
TOKENS = []

def PrintCurrentTokenInfoToScreen():
    print('Token: {0}\t\tLexeme: {1}'.format(TOKENS[index].token_type, TOKENS[index].lexeme))

def PrintCurrentTokenInfoToFile():
    OUTPUT_FILE.write('Token: {0}\t\tLexeme: {1}\n'.format(TOKENS[index].token_type, TOKENS[index].lexeme))
   
def SayErrorAndDie(description):
    print(ERROR_STRING.format(description, TOKENS[index].line_number, TOKENS[index].token_type, TOKENS[index].lexeme))
    print('Failed to parse file "{0}" exiting'.format(INPUT_FILE))
    sys.exit(1)

def PrintParseInfoToScreen(leftside, rightside):
    print('\t{0} -> {1}'.format(leftside, rightside))

def PrintParseInfoToFile(leftside, rightside):
    OUTPUT_FILE.write('\t{0} -> {1}\n'.format(leftside, rightside))

def Parser(input_file, output_file=None):
    """
    @brief Outputs how to each token was parsed

    @param[in] input_file The source code we are parsing
    @param[in] output_file The file to write all output to
    """
    # Allow us to mutate globals
    global index
    global INPUT_FILE
    global TOKENS
    global OUTPUT_FILE
    global PrintParseInfo
    global PrintCurrentTokenInfo
    
    INPUT_FILE = input_file
    index = 0
    TOKENS = Lexer(input_file)
    if output_file is not None:
        OUTPUT_FILE = open(output_file, 'w')
        PrintCurrentTokenInfo = PrintCurrentTokenInfoToFile
        PrintParseInfo = PrintParseInfoToFile
    else:
        PrintCurrentTokenInfo = PrintCurrentTokenInfoToScreen
        PrintParseInfo = PrintParseInfoToScreen
        
    PrintCurrentTokenInfo = p 
    PrintParseInfo = p2

    Rat15S()

def Empty():
    pass

def Read():
    global index
    if TOKENS[index] == '(':
        index += 1
        PrintIDs()
        if TOKENS[index] == ')':
            PrintCurrentTokenInfo()
            index += 1
        else:
            SayErrorAndDie('Expected separator ")"')

        if TOKENS[index] == ';':
            PrintCurrentTokenInfo()
            index += 1
        else:
            SayErrorAndDie('Expected separator ";"')
    else:
        SayErrorAndDie('Expected separator "("')

def Write():
    global index
    if TOKENS[index] == '(':
        index += 1
        Expression()
        if TOKENS[index] == ')':
            index += 1
        else:
            SayErrorAndDie('Expected separator ")"')

        if TOKENS[index] == ';':
            index += 1
            AddInstruction(Instruction('STDOUT', None))
        else:
            SayErrorAndDie('Expected separator ";"')

    else:
        SayErrorAndDie('Expected separator "("')

def Compound():
    global index
    StatementList(True)

    if TOKENS[index] == '}':
        index +=1
    else:
        SayErrorAndDie('Expected separator "}"')

def If():
    global index

    else_found = False
    for token in TOKENS[index+1:]:
        if token == 'else':
            else_found = True
            break
        if token == 'endif':
            break
        if token == 'if':
            break

    if TOKENS[index] == '(':
        index += 1
    else:
        SayErrorAndDie('Expected Separator "("')
    
    Condition()
        
    if TOKENS[index] == ')':
        index += 1
        Statement()
    else:
        SayErrorAndDie('Expected separtor ")"')

        
    if else_found:
        if TOKENS[index] == 'else':
            BackPatch()
            AddInstruction(Instruction('LABEL', None))
            index += 1
            Statement()
    else:
        BackPatch()    

    if TOKENS[index] == 'endif':
        index += 1
    else:
        SayErrorAndDie('Expected keyword "endif"')

def Relop(token):
    global index
    if token == '=':
        AddInstruction(Instruction('EQU', None))
        AddInstruction(Instruction('JUMPZ', 'BACK PATCH'))
    elif token == '!=':
        AddInstruction(Instruction('EQU', None))
        AddInstruction(Instruction('JUMPZ', len(INSTRUCTIONS) + 2))
        AddInstruction(Instruction('JUMP', 'BACK PATCH'))
    elif token == '>':
        AddInstruction(Instruction('GRT', None))
        AddInstruction(Instruction('JUMPZ', 'BACK PATCH'))
    elif token == '<':
        AddInstruction(Instruction('LES', None))
        AddInstruction(Instruction('JUMPZ', 'BACK PATCH'))
    else:
        SayErrorAndDie('Expected <Relop>')
    '''
    I don't feel like implementing these.  They're really hard.

    elif token == '=>':
        return Instruction('EQU', None)
        PrintParseInfo('<Relop>', '=>')
    elif token == '<=':
        return Instruction('EQU', None)
        PrintParseInfo('<Relop>', '<=')
    '''
        
def Condition():
    global index
    Expression()
    if TOKENS[index].token_type == 'Relop':
        relop_token = TOKENS[index]
        index += 1
        Expression()
        Relop(relop_token)
    else:
        SayErrorAndDie('Expected <Relop>')

        
def While():
    global index
    jump_addr = len(INSTRUCTIONS)
    AddInstruction(Instruction('LABEL', None))
    if TOKENS[index] == '(':
        index += 1
    else:
        SayErrorAndDie('Expected separator "("')
    Condition()
    if TOKENS[index] == ')':
        index += 1
        pdb.set_trace()
        Statement()
        AddInstruction(Instruction('JUMP', jump_addr))
        BackPatch()
    else:
        SayErrorAndDie('Expected separtor ")"')


def ExpressionPrime():
    global index
    if TOKENS[index] == '+':
        index += 1
        Term()
        AddInstruction(Instruction('ADD', None))
        ExpressionPrime()
    elif TOKENS[index] == '-':
        index += 1
        Term()
        AddInstruction(Instruction('SUB', None))
        ExpressionPrime()

def TermPrime():
    global index
    if TOKENS[index] == '*':
        index += 1
        Factor()

        AddInstruction(Instruction('MUL', None))
        TermPrime()
    elif TOKENS[index] == '/':
        index += 1
        Factor()
        AddInstruction(Instruction('DIV', None))
        TermPrime()

def Factor():
    global index
    if TOKENS[index].token_type == 'Identifier':
        if IsIdentifierInSymbolTable(TOKENS[index]):
            memory_location = GetIdentifierMemoryLocation(TOKENS[index])
            index += 1
            AddInstruction(Instruction("PUSHM", memory_location))
        else:
            SayErrorAndDie('Unknown identifier encounter')
    elif TOKENS[index].token_type == 'Integer':
        AddInstruction(Instruction("PUSHI", int(TOKENS[index].lexeme)))
        index += 1
    elif TOKENS[index] == 'true':
        AddInstruction(Instruction("PUSHI", 1))
        index += 1
    elif TOKENS[index] == 'false':
        AddInstruction(Instruction("PUSHI", 0))
        index += 1
    elif TOKENS[index] == '(':
        index += 1
        i = index
        Expression()            
        if TOKENS[index] == ')':
            index += 1
        else:
            SayErrorAndDie('Expected separator ")"')

def Term():
    Factor()
    TermPrime()

def Expression():
    Term()
    ExpressionPrime()
            
def Assignment():
    global index

    if TOKENS[index] == ':=':
        index += 1
    else:
        SayErrorAndDie('Expected operator ":="')
    Expression()
    if TOKENS[index] == ';':
        index += 1
    else:
        SayErrorAndDie('Expected separator ";"')

def Statement():
    global index
    global INSTRUCTIONS
    if TOKENS[index] == '{':
        index += 1
        Compound()
    elif TOKENS[index] == 'if':
        index += 1
        If()
    elif TOKENS[index] == 'return':
        index += 1
        Return()
    elif TOKENS[index] == 'write':
        index += 1
        Write()
    elif TOKENS[index] == 'read':
        index += 1
        Read()
    elif TOKENS[index] == 'while':
        index += 1
        While()
    elif TOKENS[index].token_type == 'Identifier':
        if IsIdentifierInSymbolTable(TOKENS[index]):
            memory_location = GetIdentifierMemoryLocation(TOKENS[index])
            index += 1
            Assignment()
            AddInstruction(Instruction('POPM', memory_location))
        else:
            SayErrorAndDie('Unknown identifier encounter')
    else:
        SayErrorAndDie('Expected one of the following symbols "{", "if", "return", "write", "read", or "while"')

def StatementList(special=False):
    multiple_statements = False
    in_if_block = False
    in_compound_block = False
    num_semicolons = 0

    i = index
    num_statements = 0
    while (i < len(TOKENS)):
        if special == True:
            if TOKENS[i] in ['else', 'endif', '}']:
                break
        if TOKENS[i] == 'if':
            while TOKENS[i] != 'endif':
                i += 1
            num_statements += 1
        elif TOKENS[i] == '{':
            while TOKENS[i] != '}':
                i += 1
            if special == True:
                if TOKENS[i] == '}':
                    break
            num_statements += 1
        else:
            while TOKENS[i] != ';':
                i += 1
            num_statements += 1

        if num_statements > 1:
            multiple_statements = True
            break
        i += 1

    if multiple_statements:
        Statement()
        if special == True:
            StatementList(True)
        else:
            StatementList()
    else:
        Statement()

def PrintIDs():
    global index
    multiple_ids = False
    for token in TOKENS[index+1:]:
        if token.lexeme in ';:[':
            break
        elif token == ',':
            multiple_ids = True
            break

    if multiple_ids:
        if TOKENS[index].token_type == 'Identifier':
            AddInstruction(Instruction('STDIN', None))
            memory_location = GetIdentifierMemoryLocation(TOKENS[index])
            AddInstruction(Instruction('POPM', memory_location))
            index += 1
            if TOKENS[index].lexeme == ',':
                index += 1
            else:
                SayErrorAndDie('Expected Separator ","')
        else:
            SayErrorAndDie('Expected Identifier')
        PrintIDs()
    else:
        if (TOKENS[index].token_type == 'Identifier'):
            AddInstruction(Instruction('STDIN', None))
            memory_location = GetIdentifierMemoryLocation(TOKENS[index])
            AddInstruction(Instruction('POPM', memory_location))
            index += 1
        else:
            SayErrorAndDie('Expected Identifier')

def IDs():
    global index
    multiple_ids = False
    for token in TOKENS[index+1:]:
        if token.lexeme in ';:[':
            break
        elif token == ',':
            multiple_ids = True
            break

    if multiple_ids:
        if TOKENS[index].token_type == 'Identifier':
            InsertIntoSymbolTable(TOKENS[index], CURRENT_DATA_TYPE)
            index += 1
            if TOKENS[index].lexeme == ',':
                index += 1
            else:
                SayErrorAndDie('Expected Separator ","')
        else:
            SayErrorAndDie('Expected Identifier')
        IDs()
    else:
        if (TOKENS[index].token_type == 'Identifier'):
            InsertIntoSymbolTable(TOKENS[index], CURRENT_DATA_TYPE)
            index += 1
        else:
            SayErrorAndDie('Expected Identifier')

def Qualifier():
    global index
    global CURRENT_DATA_TYPE
    if TOKENS[index] == 'boolean':
        CURRENT_DATA_TYPE = 'boolean'
        index += 1
    elif TOKENS[index] == 'int':
        CURRENT_DATA_TYPE = 'int'
        index += 1
    else:
        SayErrorAndDie('Expected Qualifier "int", or "boolean"')

def Declaration():
    global index
    global CURRENT_DATA_TYPE
    Qualifier()
    IDs()
    CURRENT_DATA_TYPE = None

def DeclarationList():
    global index
    multiple_declarations = False
    num_keywords = 0
    for token in TOKENS[index:]:
        if token.token_type == 'Keyword':
            num_keywords += 1
        if num_keywords > 1:
            multiple_declarations = True
            break
        if token == '@@':
            break

    if multiple_declarations:
        Declaration()
        if TOKENS[index] == ';':
            index += 1
            DeclarationList()
        else:
            SayErrorAndDie('Expected separator ";"')
    else:
        Declaration()
        if TOKENS[index] == ';':
            index += 1
        else:
            SayErrorAndDie('Expected separator ";"')
        
def OptDeclarationList():
    if TOKENS[index].lexeme == '@@':
        Empty()
    else:
        DeclarationList()
        
def Rat15S():
    global index
    global SYMBOL_TABLE
    SYMBOL_TABLE = []
    if TOKENS[index].lexeme == '@@':
        index += 1
        OptDeclarationList()
        if TOKENS[index].lexeme == '@@':
            index += 1
            StatementList()
        else:
            SayErrorAndDie('Expected separator "@@"')
    else:
        SayErrorAndDie('Expected separator "@@"')

    AddInstruction(Instruction('LABEL', None))
    DisplaySymbolTable()
    print('')
    DisplayInstructionTable()

def DisplayInstructionTable():
    print('Num\tInstruction\tOperand')
    for i in range(len(INSTRUCTIONS)):
        instruction = INSTRUCTIONS[i]
        print('{0}\t{1}\t\t{2}'.format(i, instruction.command, instruction.operand))
        
def DisplaySymbolTable():
    print("IDENTIFIED\tMEMORY LOCATION\t\tTYPE")
    for (token, memory_location, data_type) in SYMBOL_TABLE:
        print('{0}\t\t{1}\t\t\t{2}'.format(token.lexeme, memory_location, data_type))

def InsertIntoSymbolTable(token, data_type):
    global SYMBOL_TABLE
    global CURRENT_MEMORY_LOCATION
    if IsIdentifierInSymbolTable(token):
        SayErrorAndDie('"{}" already defined as identifier'.format(token.lexeme))
    SYMBOL_TABLE.append((token, CURRENT_MEMORY_LOCATION, data_type))
    CURRENT_MEMORY_LOCATION += 1

def IsIdentifierInSymbolTable(token):
    return True if token.lexeme in [t.lexeme for (t, x, y) in SYMBOL_TABLE] else False

def GetIdentifierMemoryLocation(token):
    memory_location = None
    for (t, mem_loc, _) in SYMBOL_TABLE:
        if t.lexeme == token.lexeme:
            memory_location = mem_loc
            break
    return memory_location

def GetIdentifierDataType(token):
    token_data_type = None
    for (t, _, data_type) in SYMBOL_TABLE:
        if token.lexeme == t.lexeme:
            token_data_type = data_type
            break
    return token_data_type

def AddInstruction(instruction):
    global INSTRUCTIONS
    INSTRUCTIONS.append(instruction)
 
def BackPatch():
    next_instruction = len(INSTRUCTIONS)
    for i in range(len(INSTRUCTIONS)-1, -1, -1):
        if INSTRUCTIONS[i].operand == 'BACK PATCH':
            INSTRUCTIONS[i].operand = next_instruction
            break
        
